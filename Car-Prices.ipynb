{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Araba FiyatlarÄ± (Car Prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ Bu challengeâ€™Ä±n amacÄ±, bir dataset hazÄ±rlamak ve ÅŸimdiye kadar Ã¶ÄŸrendiÄŸiniz bazÄ± feature selection tekniklerini uygulamaktÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš— Arabalarla ilgili bir veri setiyle Ã§alÄ±ÅŸÄ±yoruz ve bir arabanÄ±n pahalÄ± mÄ± yoksa ucuz mu olduÄŸunu tahmin etmek istiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# SayÄ±sal bir Ã¶zelliÄŸin normal daÄŸÄ±lÄ±m gÃ¶sterip gÃ¶stermediÄŸini kontrol etme\n",
    "from statsmodels.graphics.gofplots import qqplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://d32aokrjazspmn.cloudfront.net/materials/ML_Cars_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ CSV dosyasÄ±nÄ± `df` adlÄ± bir veri Ã§erÃ§evesine yÃ¼kleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ Datasetâ€™in aÃ§Ä±klamasÄ± [burada](https://drive.google.com/file/d/1ADSyjWfRGYqdXwCCN4PPC7PjQeMZ-ap-/view?usp=sharing ) mevcuttur. Egzersiz boyunca buna mutlaka referans verin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Yinelenenler (Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Varsa, veri kÃ¼mesinden yinelenenleri kaldÄ±rÄ±n. â“\n",
    "\n",
    "*Veri Ã§erÃ§evesini `df`* Ã¼zerine yazÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)  Eksik deÄŸerler (Missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Eksik deÄŸerleri bulun ve bunlarÄ± ya `strategy = \"most frequent\"` (kategorik deÄŸiÅŸkenler iÃ§in) ya da `strategy = \"median\"` (sayÄ±sal deÄŸiÅŸkenler iÃ§in) kullanarak doldurun â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Total Missing  Percentage (%)\n",
      "enginelocation             10        5.235602\n",
      "carwidth                    2        1.047120\n",
      "aspiration                  0        0.000000\n",
      "curbweight                  0        0.000000\n",
      "enginetype                  0        0.000000\n",
      "cylindernumber              0        0.000000\n",
      "stroke                      0        0.000000\n",
      "peakrpm                     0        0.000000\n",
      "price                       0        0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data = pd.DataFrame({\n",
    "    'Total Missing': df.isnull().sum(),\n",
    "    'Percentage (%)': (df.isnull().sum() / len(df)) * 100\n",
    "}).sort_values(by='Percentage (%)', ascending=False)\n",
    "\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['carwidth'] = pd.to_numeric(df['carwidth'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 0 to 204\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   aspiration      191 non-null    object \n",
      " 1   enginelocation  181 non-null    object \n",
      " 2   carwidth        185 non-null    float64\n",
      " 3   curbweight      191 non-null    int64  \n",
      " 4   enginetype      191 non-null    object \n",
      " 5   cylindernumber  191 non-null    object \n",
      " 6   stroke          191 non-null    float64\n",
      " 7   peakrpm         191 non-null    int64  \n",
      " 8   price           191 non-null    object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `carwidth`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>carwidth</code> sÃ¼tununda eksik deÄŸerler birden fazla ÅŸekilde temsil edilmektedir. BazÄ±larÄ± <code>np.nan</code>, bazÄ±larÄ± ise <code>*</code> olarak yer alÄ±r. Bunlar tespit edildikten sonra, eksik deÄŸerler verinin %30â€™undan daha azÄ±nÄ± oluÅŸturduÄŸu iÃ§in medyan deÄŸerle doldurulabilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X_train[['carwidth']] = num_imputer.fit_transform(X_train[['carwidth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['carwidth']] = num_imputer.transform(X_test[['carwidth']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginelocation</code> kategorik bir feature olduÄŸundan ve kategorilerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu <code>front</code> olduÄŸu iÃ§in, en sÄ±k gÃ¶rÃ¼len deÄŸerle doldurun.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['enginelocation']] = cat_imputer.fit_transform(X_train[['enginelocation']])\n",
    "X_test[['enginelocation']] = cat_imputer.transform(X_test[['enginelocation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in Train: 0\n",
      "Missing in Test: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing in Train: {X_train['enginelocation'].isnull().sum()}\")\n",
    "print(f\"Missing in Test: {X_test['enginelocation'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[['carwidth']] = num_imputer.fit_transform(df[['carwidth']])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[['enginelocation']] = cat_imputer.fit_transform(df[['enginelocation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/ilos/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/ilos/code/S16D2-S-Data-car-prices/tests\n",
      "plugins: anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_engine_location \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.51s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) SayÄ±sal Ã¶zelliklerin Ã¶lÃ§eklendirilmesi (Scaling the numerical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 0 to 204\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   aspiration      191 non-null    object \n",
      " 1   enginelocation  181 non-null    object \n",
      " 2   carwidth        185 non-null    float64\n",
      " 3   curbweight      191 non-null    int64  \n",
      " 4   enginetype      191 non-null    object \n",
      " 5   cylindernumber  191 non-null    object \n",
      " 6   stroke          191 non-null    float64\n",
      " 7   peakrpm         191 non-null    int64  \n",
      " 8   price           191 non-null    object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# HatÄ±rlatma olarak, DataFrame hakkÄ±nda bazÄ± bilgiler\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carwidth', 'curbweight', 'stroke', 'peakrpm'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ve iÅŸte Ã¶lÃ§eklendirmemiz gereken veri kÃ¼mesinin sayÄ±sal Ã¶zellikleri\n",
    "numerical_features = df.select_dtypes(exclude=['object']).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: SayÄ±sal featureâ€™larÄ±n Ã¶lÃ§eklenmesi** â“\n",
    "\n",
    "SayÄ±sal featureâ€™larÄ± aykÄ±rÄ± deÄŸerler (outliers) ve daÄŸÄ±lÄ±mlarÄ± aÃ§Ä±sÄ±ndan inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki yÃ¶ntemleri uygulayÄ±n:\n",
    "- Robust Scaler\n",
    "- Standard Scaler\n",
    "\n",
    "DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ deÄŸerlerle orijinal sÃ¼tunlarÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `peakrpm` , `carwidth` , & `stroke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "\n",
    "    \n",
    "â„¹ï¸ <code>peakrpm</code>, <code>carwidth</code> ve <code>stroke</code> normal daÄŸÄ±lÄ±ma sahiptir ancak aynÄ± zamanda bazÄ± aykÄ±rÄ± deÄŸerler (outlier) iÃ§erir. Bu nedenle `RobustScaler()` kullanÄ±lmasÄ± tavsiye edilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `curbweight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>curbweight</code> normal bir daÄŸÄ±lÄ±ma sahiptir ve aykÄ±rÄ± deÄŸer (outlier) iÃ§ermez. Bu nedenle Standard Scaler ile Ã¶lÃ§eklenebilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/ilos/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/ilos/code/S16D2-S-Data-car-prices/tests\n",
      "plugins: anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_scaling.py::TestScaling::test_carwidth \u001b[31mFAILED\u001b[0m\u001b[31m                       [ 25%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_curbweight \u001b[31mFAILED\u001b[0m\u001b[31m                     [ 50%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_peakrpm \u001b[31mFAILED\u001b[0m\u001b[31m                        [ 75%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_stroke \u001b[31mFAILED\u001b[0m\u001b[31m                         [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________ TestScaling.test_carwidth ___________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_carwidth>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_carwidth\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.carwidth.median() , \u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 65.5 != 0\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:7: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ TestScaling.test_curbweight __________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_curbweight>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_curbweight\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.curbweight.max() < \u001b[94m3\u001b[39;49;00m, \u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: False != True\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:11: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestScaling.test_peakrpm ___________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_peakrpm>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_peakrpm\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.peakrpm.median(), \u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 5100.0 != 0\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestScaling.test_stroke ____________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_stroke>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stroke\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.stroke.median() , \u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 3.29 != 0\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:9: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_scaling.py::\u001b[1mTestScaling::test_carwidth\u001b[0m - AssertionError: 65.5 != 0\n",
      "\u001b[31mFAILED\u001b[0m test_scaling.py::\u001b[1mTestScaling::test_curbweight\u001b[0m - AssertionError: False != True\n",
      "\u001b[31mFAILED\u001b[0m test_scaling.py::\u001b[1mTestScaling::test_peakrpm\u001b[0m - AssertionError: 5100.0 != 0\n",
      "\u001b[31mFAILED\u001b[0m test_scaling.py::\u001b[1mTestScaling::test_stroke\u001b[0m - AssertionError: 3.29 != 0\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m4 failed\u001b[0m\u001b[31m in 0.48s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/scaling.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed scaling step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = df\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Kategorik Ã¶zelliklerin kodlanmasÄ± (Encoding the categorical features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Kategorik deÄŸiÅŸkenlerin encode edilmesi** â“\n",
    "\n",
    "ğŸ‘‡ Encode edilmesi gereken featureâ€™larÄ± inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki teknikleri uygulayÄ±n:\n",
    "\n",
    "- One-hot encoding\n",
    "- Manuel ordinal encoding\n",
    "\n",
    "DataFrame iÃ§inde, orijinal featureâ€™larÄ± encode edilmiÅŸ versiyonlarÄ±yla deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `aspiration` & `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>aspiration</code> ve <code>enginelocation</code> ikili (binary) kategorik featureâ€™lardÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginetype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginetype</code> Ã§ok kategorili (multicategorical) bir featureâ€™dÄ±r ve One-hot encoding uygulanmalÄ±dÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cylindernumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "â„¹ï¸ <code>cylindernumber</code> sÄ±ralÄ± (ordinal) bir featureâ€™dÄ±r ve sayÄ±sal deÄŸerlere manuel olarak encode edilmelidir.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ ArtÄ±k `cylindernumber`â€™Ä± 2 ile 12 arasÄ±nda sayÄ±sal bir featureâ€™a dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼ze gÃ¶re, bunu Ã¶lÃ§eklendirmeniz gerekiyor â“\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "`cylindernumber`â€™Ä±n mevcut daÄŸÄ±lÄ±mÄ±na bakÄ±n ve kendinize ÅŸu sorularÄ± sorun:\n",
    "- Ã–lÃ§ekleme, bir featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±nÄ± etkiler mi?\n",
    "- Bu featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±na gÃ¶re en uygun Ã¶lÃ§ekleme yÃ¶ntemi hangisidir?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><i>Ã–lÃ§ekleme ve encoding iÅŸlemlerinden sonra DataFrameâ€™inizin nasÄ±l gÃ¶rÃ¼nmesi gerektiÄŸine dair bir ekran gÃ¶rÃ¼ntÃ¼sÃ¼ aÅŸaÄŸÄ±dadÄ±r</i></summary>\n",
    "    \n",
    "    \n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/car_price_after_scaling_and_encoding.png\">    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‡ Hedef `price`Ä± kodlayÄ±n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>price</code> target deÄŸiÅŸkendir ve LabelEncoder ile encode edilmelidir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/ilos/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/ilos/code/S16D2-S-Data-car-prices/tests\n",
      "plugins: anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_encoding.py::TestEncoding::test_aspiration \u001b[31mFAILED\u001b[0m\u001b[31m                   [ 25%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginelocation \u001b[31mFAILED\u001b[0m\u001b[31m               [ 50%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginetype \u001b[31mFAILED\u001b[0m\u001b[31m                   [ 75%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_price \u001b[31mFAILED\u001b[0m\u001b[31m                        [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ TestEncoding.test_aspiration _________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_aspiration>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_aspiration\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.aspiration.max(), \u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 'turbo' != 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m_______________________ TestEncoding.test_enginelocation _______________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_enginelocation>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_enginelocation\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.enginelocation.max(), \u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/series.py\u001b[0m:6517: in max\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDFrame.max(\u001b[96mself\u001b[39;49;00m, axis, skipna, numeric_only, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12404: in max\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._stat_function(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12377: in _stat_function\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._reduce(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/series.py\u001b[0m:6457: in _reduce\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m op(delegate, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:147: in f\n",
      "    \u001b[0mresult = alt(values, axis=axis, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:404: in new_func\n",
      "    \u001b[0mresult = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:1098: in reduction\n",
      "    \u001b[0mresult = \u001b[96mgetattr\u001b[39;49;00m(values, meth)(axis)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "a = array(['front', 'front', 'front', 'front', 'front', 'front', 'front',\n",
      "       'front', 'front', 'front', 'front', 'fron...t', 'front',\n",
      "       -inf, 'front', 'front', 'front', 'front', 'front', 'front',\n",
      "       'front', 'front'], dtype=object)\n",
      "axis = None, out = None, keepdims = False, initial = <no value>, where = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_amax\u001b[39;49;00m(a, axis=\u001b[94mNone\u001b[39;49;00m, out=\u001b[94mNone\u001b[39;49;00m, keepdims=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "              initial=_NoValue, where=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m umr_maximum(a, axis, \u001b[94mNone\u001b[39;49;00m, out, keepdims, initial, where)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: '>=' not supported between instances of 'str' and 'float'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../.pyenv/versions/workintech/lib/python3.12/site-packages/numpy/core/_methods.py\u001b[0m:41: TypeError\n",
      "\u001b[31m\u001b[1m_________________________ TestEncoding.test_enginetype _________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_enginetype>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_enginetype\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.result.dataset.columns) > \u001b[94m13\u001b[39;49;00m, \u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: False != True\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:9: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestEncoding.test_price ____________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_price>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_price\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.price.max(), \u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: 'expensive' != 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:13: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_encoding.py::\u001b[1mTestEncoding::test_aspiration\u001b[0m - AssertionError: 'turbo' != 1\n",
      "\u001b[31mFAILED\u001b[0m test_encoding.py::\u001b[1mTestEncoding::test_enginelocation\u001b[0m - TypeError: '>=' not supported between instances of 'str' and 'float'\n",
      "\u001b[31mFAILED\u001b[0m test_encoding.py::\u001b[1mTestEncoding::test_enginetype\u001b[0m - AssertionError: False != True\n",
      "\u001b[31mFAILED\u001b[0m test_encoding.py::\u001b[1mTestEncoding::test_price\u001b[0m - AssertionError: 'expensive' != 1\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m4 failed\u001b[0m\u001b[31m in 0.66s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/encoding.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed encoding step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Temel Modelleme (Base Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘ Veri kÃ¼mesi Ã¶n iÅŸleme tabi tutuldu ve artÄ±k modele uyarlanmaya hazÄ±r. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Bir classification modelini ilk kez deÄŸerlendirme** â“\n",
    "\n",
    "Ã–n iÅŸlenmiÅŸ bu dataset Ã¼zerinde bir `LogisticRegression` modeli iÃ§in cross-validation Ã§alÄ±ÅŸtÄ±rÄ±n ve elde edilen skoru `base_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnbresult\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m ChallengeResult(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m                          score \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model_score\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m result\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcheck())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model_score' is not defined"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('base_model',\n",
    "                         score = base_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Ã–zellik SeÃ§imi  (Feature Selection (with _Permutation Importance_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘©ğŸ»â€ğŸ« Bir featureâ€™Ä±n targetâ€™Ä± tahmin etmede gerÃ§ekten Ã¶nemli olup olmadÄ±ÄŸÄ±nÄ± tespit etmenin gÃ¼Ã§lÃ¼ bir yolu ÅŸudur:\n",
    "\n",
    "1. Bir model Ã§alÄ±ÅŸtÄ±rÄ±n ve skorunu Ã¶lÃ§Ã¼n  \n",
    "2. Bu featureâ€™Ä± karÄ±ÅŸtÄ±rÄ±n (shuffle edin), modeli tekrar Ã§alÄ±ÅŸtÄ±rÄ±n ve skoru tekrar Ã¶lÃ§Ã¼n  \n",
    "    - EÄŸer performans **belirgin ÅŸekilde dÃ¼ÅŸerse**, bu feature Ã¶nemlidir ve **Ã§Ä±karÄ±lmamalÄ±dÄ±r**\n",
    "    - EÄŸer performans **Ã§ok fazla dÃ¼ÅŸmezse**, bu feature **elenebilir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Sorular** â“\n",
    "\n",
    "1. Modele en az bilgi katkÄ±sÄ± saÄŸlayan featureâ€™larÄ± tespit etmek iÃ§in feature permutation uygulayÄ±n.\n",
    "2. Model performansÄ±nÄ±n belirgin ÅŸekilde dÃ¼ÅŸmeye baÅŸladÄ±ÄŸÄ±nÄ± fark edene kadar zayÄ±f featureâ€™larÄ± datasetâ€™ten Ã§Ä±karÄ±n.\n",
    "3. Elde ettiÄŸiniz yeni gÃ¼Ã§lÃ¼ feature setâ€™i ile yeni bir modeli cross-validation ile deÄŸerlendirin ve skorunu `strong_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('strong_model',\n",
    "                         score = strong_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus -  Verilerinizi sÄ±nÄ±flandÄ±rma (Stratifying your data) âš–ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ Veriyi training ve testing olarak bÃ¶lerken, datasetâ€™imizdeki kategorik deÄŸiÅŸkenlerin oranÄ±na dikkat etmemiz gerekir â€” ister target `y`â€™nin sÄ±nÄ±flarÄ± olsun ister `X` iÃ§indeki kategorik bir feature olsun.\n",
    "\n",
    "AÅŸaÄŸÄ±da bir Ã¶rneÄŸe bakalÄ±m ğŸ‘‡\n",
    "\n",
    "â“ Orijinal `X` ve `y` verinizi sklearnâ€™in `train_test_split` fonksiyonunu kullanarak training ve testing olarak ayÄ±rÄ±n; karÅŸÄ±laÅŸtÄ±rÄ±labilir sonuÃ§lar elde etmek iÃ§in `random_state=1` ve `test_size=0.3` kullanÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Training datasetâ€™inizde ve testing datasetâ€™inizde `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± kontrol edin.\n",
    "\n",
    "> _Ham `df` iÃ§inde bu orana baktÄ±ÄŸÄ±nÄ±zda, yaklaÅŸÄ±k **%50 / %50** olmasÄ± gerekir._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â˜ï¸ HÃ¢lÃ¢ yaklaÅŸÄ±k olarak **%50 / %50** civarÄ±nda olmalÄ±.\n",
    "\n",
    "***Peki random stateâ€™i deÄŸiÅŸtirirsek ne olur?***\n",
    "\n",
    "â“ `random_state` deÄŸerlerini **1â€™den 10â€™a** kadar dÃ¶ngÃ¼ye alÄ±n ve her seferinde training ve testing datasetâ€™lerindeki `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± hesaplayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her seferinde oranlarÄ±n deÄŸiÅŸtiÄŸini, hatta bazen oldukÃ§a ciddi ÅŸekilde deÄŸiÅŸtiÄŸini gÃ¶zlemleyeceksiniz ğŸ˜±! Bu durum model performansÄ±nÄ± etkileyebilir.\n",
    "\n",
    "â“ `train_test_split(random_state=1)` kullanÄ±larak eÄŸitilen bir Logistic Regression modelinin test skorunu,  \n",
    "`random_state=9` kullanÄ±larak eÄŸitilen modelin test skoru ile karÅŸÄ±laÅŸtÄ±rÄ±n â“\n",
    "\n",
    "EÄŸitimi training data Ã¼zerinde yapmayÄ± ve skoru testing data Ã¼zerinde hesaplamayÄ± unutmayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ `random_state=9` ile Ã§ok daha dÃ¼ÅŸÃ¼k bir skor gÃ¶rmelisiniz; Ã§Ã¼nkÃ¼ bu test setindeki sÄ±nÄ±f **1** araÃ§larÄ±n oranÄ± %34.5 iken, training setinde bu oran %57.9â€™a, hatta orijinal datasetâ€™te yaklaÅŸÄ±k %50â€™ye yakÄ±ndÄ±r.\n",
    "\n",
    "Bu durum oldukÃ§a Ã¶nemlidir; Ã§Ã¼nkÃ¼ datasetâ€™te oluÅŸan bu **rastlantÄ±sal dengesizlik**, yalnÄ±zca model performansÄ±nÄ± dÃ¼ÅŸÃ¼rmekle kalmaz, aynÄ± zamanda eÄŸitim veya deÄŸerlendirme sÄ±rasÄ±nda â€œgerÃ§ekliÄŸiâ€ de bozabilir ğŸ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Peki bu sorunu nasÄ±l Ã§Ã¶zebiliriz? Tren seti ve test seti arasÄ±nda sÄ±nÄ±flarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± nasÄ±l aynÄ± tutabiliriz? ğŸ”§***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Neyse ki sklearnâ€™de, estimator (yani model) bir classifier olduÄŸunda ve target bir sÄ±nÄ±f olduÄŸunda, bu durum `cross_validate` tarafÄ±ndan otomatik olarak ele alÄ±nÄ±r. ğŸ“š [**sklearn.model_selection.cross_validate**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) dokÃ¼mantasyonunda `cv` parametresini inceleyin.\n",
    "\n",
    "Ã‡Ã¶zÃ¼m, aÅŸaÄŸÄ±dakini kullanmaktÄ±r:\n",
    "\n",
    "> ğŸ“š [**Stratification (Katmanlama)**](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hedefin tabakalaÅŸmasÄ± (Stratification of the target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ ***Stratification*** tekniÄŸini `train_test_split` iÃ§inde de kullanabiliriz.\n",
    "\n",
    "â“ Bu kez **1â€™den 10â€™a** kadar olan `random_state` dÃ¶ngÃ¼sÃ¼nÃ¼ tekrar Ã§alÄ±ÅŸtÄ±rÄ±n, ancak bu sefer holdout yÃ¶ntemine ***`stratify=y`*** parametresini de ekleyin. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ Random state deÄŸiÅŸse bile, training ve testing verilerindeki sÄ±nÄ±f oranlarÄ±, orijinal `y` iÃ§indeki oranlarla aynÄ± tutulur. Ä°ÅŸte _stratification_ (katmanlama) tam olarak budur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` fonksiyonunu `stratify` parametresiyle kullandÄ±ÄŸÄ±mÄ±zda, training ve testing verileri arasÄ±nda **bir featureâ€™Ä±n oranlarÄ±nÄ± da koruyabiliriz**. Bu, Ã¶zellikle aÅŸaÄŸÄ±daki durumlarda son derece Ã¶nemlidir:\n",
    "\n",
    "- Churn tahmininde erkek ve kadÄ±n mÃ¼ÅŸteri oranlarÄ±nÄ± korumak ğŸ™‹â€â™‚ï¸ ğŸ™‹\n",
    "- Ev fiyatlarÄ±nÄ± tahmin ederken bÃ¼yÃ¼k ve kÃ¼Ã§Ã¼k evlerin oranlarÄ±nÄ± korumak ğŸ  ğŸ°\n",
    "- Bir sonraki Ã¼rÃ¼nÃ¼ Ã¶nerirken 1â€“5 arasÄ± review score daÄŸÄ±lÄ±mÄ±nÄ± (multiclass!) korumak ğŸ›ï¸\n",
    "- vb.\n",
    "\n",
    "Ã–rneÄŸin, bizim datasetâ€™imizde `aspiration` featureâ€™Ä±nÄ±n training ve testing verilerinde aynÄ± oranda kalmasÄ±nÄ± istiyorsak, ÅŸu ÅŸekilde yazabiliriz:\n",
    "\n",
    "`train_test_split(X, y, test_size=0.3, stratify=X.aspiration)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi, **`cross_validate` [target deÄŸiÅŸkeni otomatik olarak stratify edebilir](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#:~:text=For%20int/None%20inputs%2C%20if%20the%20estimator%20is%20a%20classifier%20and%20y%20is%20either%20binary%20or%20multiclass%2C%20StratifiedKFold%20is%20used.)**, ancak **featureâ€™lar iÃ§in bunu yapmaz** ğŸ¤” Bunun iÃ§in biraz ekstra Ã§alÄ±ÅŸmaya ihtiyacÄ±mÄ±z var.\n",
    "\n",
    "Bunun iÃ§in `StratifiedKFold` kullanmamÄ±z gerekiyor ğŸ”¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabakalaÅŸma (Stratification - generalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Veriyi 5 foldâ€™a bÃ¶lecek bir stratified k-fold oluÅŸturma\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "# .split() metodu bir iterator oluÅŸturur; 'X.aspiration' stratify edeceÄŸimiz featureâ€™dÄ±r\n",
    "for train_indices, test_indices in skf.split(X, X.aspiration):\n",
    "\n",
    "    # 'train_indices' ve 'test_indices', orantÄ±lÄ± bÃ¶lÃ¼nmeler Ã¼reten indeks listeleridir\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    # modeli baÅŸlatma ve eÄŸitme\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # en sonunda 5 foldâ€™un ortalamasÄ±nÄ± almak iÃ§in skoru listeye ekleme\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! TÃ¼m veri setini hazÄ±rladÄ±nÄ±z, Ã¶zellik seÃ§imi yaptÄ±nÄ±z ve hatta tabakalaÅŸma hakkÄ±nda bilgi edindiniz ğŸ’ª.\n",
    "\n",
    "ğŸ’¾ Not defterinizi git add/commit/push yapmayÄ± unutmayÄ±n...\n",
    "\n",
    "ğŸš€ ... ve bir sonraki challenge'a geÃ§in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
